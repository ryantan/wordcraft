# Story 4.8: Test and Validate Adaptive Engine

## Status

Draft

## Story

**As a** developer,
**I want** to validate that the adaptive engine produces sensible, effective learning paths,
**so that** I'm confident it will help children learn effectively.

## Acceptance Criteria

1. Integration tests simulate full game sessions with various performance patterns
2. Tests verify: confidence scores increase with correct answers, decrease with errors
3. Tests verify: low-confidence words are prioritized over high-confidence words
4. Tests verify: learning style detection converges on correct profile given biased data
5. Tests verify: game selection matches detected learning style over time
6. Tests verify: difficulty adjusts appropriately to performance trends
7. Manual testing with real game play validates adaptive behavior feels natural
8. Documentation explains adaptive engine behavior and tuning parameters

## Tasks / Subtasks

- [ ] Create comprehensive integration test suite (AC: 1)
  - [ ] Create test file `/__tests__/integration/adaptive-engine-validation.test.ts`
  - [ ] Setup test utilities for simulating game sessions
  - [ ] Create test data generators for various performance patterns
  - [ ] Mock IndexedDB for test isolation

- [ ] Test confidence score behavior (AC: 2)
  - [ ] Simulate 10 correct answers for a word
  - [ ] Verify confidence increases from 0% to >80%
  - [ ] Simulate 5 correct, 5 incorrect (mixed)
  - [ ] Verify confidence stays moderate (~50-60%)
  - [ ] Simulate pattern: correct → correct → incorrect
  - [ ] Verify confidence decreases after failure
  - [ ] Verify recency bias: recent failure impacts more than old failure

- [ ] Test word prioritization (AC: 3)
  - [ ] Setup word list with varied confidence:
    - Word A: 90% (mastered)
    - Word B: 50% (progressing)
    - Word C: 20% (struggling)
  - [ ] Simulate session and track word order
  - [ ] Verify Word C appears first
  - [ ] Verify Word C appears 2-3 times
  - [ ] Verify Word A appears 0-1 times
  - [ ] Assert struggling words get more practice time

- [ ] Test learning style detection (AC: 4)
  - [ ] Simulate 20 games with 100% success on visual games
  - [ ] Simulate 20 games with 50% success on kinesthetic games
  - [ ] Verify profile converges to: ~70% visual, ~30% kinesthetic
  - [ ] Simulate balanced performance across all styles
  - [ ] Verify profile stays balanced ~33% each
  - [ ] Test confidence score increases with more data

- [ ] Test adaptive game selection (AC: 5)
  - [ ] Setup visual learner profile (70% visual)
  - [ ] Simulate 100 game selections
  - [ ] Verify 60-70 games are visual type
  - [ ] Verify no game repeats consecutively
  - [ ] Verify variety maintained across session
  - [ ] Test with balanced profile → verify balanced selection

- [ ] Test difficulty adjustment (AC: 6)
  - [ ] Simulate 3 consecutive correct answers
  - [ ] Verify difficulty increases (easy → medium)
  - [ ] Simulate 2 consecutive incorrect answers
  - [ ] Verify difficulty decreases (hard → medium)
  - [ ] Simulate success rate >85% over 10 games
  - [ ] Verify difficulty nudges upward
  - [ ] Simulate success rate <60% over 10 games
  - [ ] Verify difficulty nudges downward

- [ ] Test spaced repetition scheduling (AC: 2, 3)
  - [ ] Setup word in Box 1 (struggling)
  - [ ] Simulate correct answer
  - [ ] Verify word moves to Box 2
  - [ ] Verify next review date = tomorrow
  - [ ] Simulate incorrect answer from Box 4
  - [ ] Verify word demotes to Box 1
  - [ ] Test that mastered words (Box 5) have 14-day intervals

- [ ] Test complete learning flow end-to-end
  - [ ] Simulate new child starting with 10-word list
  - [ ] All words start at 0% confidence
  - [ ] Simulate realistic performance (70% accuracy)
  - [ ] Track confidence progression over 5 sessions
  - [ ] Verify some words reach mastery (>80%)
  - [ ] Verify struggling words get more practice
  - [ ] Verify session lengths are reasonable (10-15 words)

- [ ] Manual testing with real gameplay (AC: 7)
  - [ ] Play through actual game session as a tester
  - [ ] Track word appearances and difficulty
  - [ ] Verify experience feels adaptive, not random
  - [ ] Verify difficulty adjustments feel appropriate
  - [ ] Document any issues or unexpected behavior
  - [ ] Test with different performance patterns (all correct, all wrong, mixed)

- [ ] Create adaptive engine documentation (AC: 8)
  - [ ] Create file `/docs/adaptive-engine-guide.md`
  - [ ] Explain confidence scoring algorithm and thresholds
  - [ ] Explain spaced repetition boxes and intervals
  - [ ] Explain learning style detection and game mapping
  - [ ] Explain difficulty adjustment rules
  - [ ] Document tuning parameters and their effects
  - [ ] Provide examples of typical learning paths
  - [ ] Include troubleshooting guide for unexpected behavior

- [ ] Add observability and debugging tools
  - [ ] Create development-only adaptive engine dashboard
  - [ ] Display current confidence scores
  - [ ] Display learning style profile
  - [ ] Display review schedule (Leitner boxes)
  - [ ] Display difficulty levels
  - [ ] Add console logging for adaptive decisions (dev mode only)

- [ ] Performance testing
  - [ ] Test with large word lists (100 words)
  - [ ] Verify selection algorithms execute in <50ms
  - [ ] Test with 1000+ game results in history
  - [ ] Verify confidence calculations stay fast
  - [ ] Test IndexedDB read/write performance
  - [ ] Ensure no memory leaks during long sessions

## Dev Notes

### Architecture Context

**Testing Strategy:**
[Source: docs/ui-architecture.md#Testing Strategy]

This story focuses on **integration testing** to validate the entire adaptive engine works cohesively.

**Test Structure:**
```
__tests__/
├── integration/
│   ├── adaptive-engine-validation.test.ts   # Main validation suite
│   ├── test-utils/
│   │   ├── game-session-simulator.ts         # Simulate game play
│   │   ├── performance-patterns.ts           # Test data generators
│   │   └── assertions.ts                     # Custom assertions
```

**Test Utilities:**
```typescript
// game-session-simulator.ts
export class GameSessionSimulator {
  constructor(wordList: string[]) {
    this.words = wordList
    this.adaptiveEngine = createAdaptiveEngine()
  }

  async playWord(word: string, isCorrect: boolean) {
    const result = createGameResult(word, isCorrect)
    await this.adaptiveEngine.send({ type: 'GAME_RESULT', result })
  }

  async playSession(pattern: PerformancePattern) {
    // Simulate full session with pattern
  }

  getConfidence(word: string): number {
    return this.adaptiveEngine.getSnapshot().context.wordConfidences.get(word)
  }

  getLearningProfile(): LearningStyleProfile {
    return this.adaptiveEngine.getSnapshot().context.learningStyle
  }
}
```

**Test Patterns:**
```typescript
// performance-patterns.ts
export const PERFORMANCE_PATTERNS = {
  PERFECT_LEARNER: {
    // 100% accuracy
    words: ['cat', 'dog', 'bird'],
    results: words.map(w => ({ word: w, isCorrect: true }))
  },

  STRUGGLING_LEARNER: {
    // 30% accuracy
    words: ['cat', 'dog', 'bird'],
    results: generateMixedResults(0.3)
  },

  VISUAL_LEARNER: {
    // High success on visual games, low on kinesthetic
    games: ['word-scramble', 'picture-reveal', 'letter-hunt'],
    results: [
      ...generateGameResults('word-scramble', 1.0),
      ...generateGameResults('letter-hunt', 0.4)
    ]
  },

  IMPROVING_LEARNER: {
    // Starts at 30%, improves to 80% over time
    words: ['cat'],
    sessions: [
      { accuracy: 0.3 },
      { accuracy: 0.5 },
      { accuracy: 0.7 },
      { accuracy: 0.8 }
    ]
  }
}
```

**Validation Assertions:**
```typescript
// Custom assertions for adaptive behavior
expect.extend({
  toShowAdaptiveBehavior(adaptiveEngine, expectedBehavior) {
    // Verify engine adapts as expected
  },

  toPrioritizeLowConfidence(wordOrder, confidenceScores) {
    // Verify low confidence words appear first
  },

  toMatchLearningStyle(gameSelections, profile) {
    // Verify game selection aligns with profile
  }
})
```

**Manual Testing Checklist:**
```markdown
## Manual Testing Scenarios

### Scenario 1: New Learner Journey
- [ ] Start with 10-word list, all 0% confidence
- [ ] Play session, achieve 70% accuracy
- [ ] Verify struggling words reappear
- [ ] Verify difficulty stays at easy-medium
- [ ] Play 5 total sessions
- [ ] Verify some words reach mastery

### Scenario 2: Visual Learner
- [ ] Intentionally perform well on visual games
- [ ] Perform poorly on kinesthetic games
- [ ] After 15 games, verify profile shows visual preference
- [ ] Verify subsequent games favor visual types

### Scenario 3: Difficulty Progression
- [ ] Start session, get 5 consecutive correct
- [ ] Verify difficulty increases
- [ ] Intentionally fail next 3
- [ ] Verify difficulty decreases

### Scenario 4: Mastered Word List
- [ ] Play until all words >80% confidence
- [ ] Verify session suggests new word list
- [ ] Verify mastered words rarely appear
```

**Performance Benchmarks:**
```typescript
describe('Adaptive Engine Performance', () => {
  it('handles large word lists efficiently', () => {
    const words = generateWords(100)
    const startTime = performance.now()

    const nextWord = selectNextWord(words, confidenceScores, schedules)

    const duration = performance.now() - startTime
    expect(duration).toBeLessThan(50) // < 50ms
  })

  it('handles large game history efficiently', () => {
    const history = generateGameResults(1000)
    const startTime = performance.now()

    const profile = detectLearningStyle(history)

    const duration = performance.now() - startTime
    expect(duration).toBeLessThan(100) // < 100ms
  })
})
```

### Dependencies

**Required:**
- Story 4.1-4.7 - ALL must be complete
- This story validates the entire Epic 4 implementation

### Testing

[Source: docs/ui-architecture.md#Testing Strategy]

**Testing Framework:** Vitest + React Testing Library + Playwright (for E2E)
**Test Locations:**
- `/__tests__/integration/adaptive-engine-validation.test.ts`
- `/__tests__/e2e/adaptive-gameplay.spec.ts`

**Run Tests:**
```bash
npm run test                  # Unit + integration tests
npm run test:e2e              # E2E adaptive gameplay tests
npm run test:all              # Full test suite
npm run test:coverage         # With coverage report
```

**Coverage Target:**
- Overall Epic 4: >70% coverage
- Adaptive algorithms: >80% coverage

### Documentation Deliverables

**File:** `/docs/adaptive-engine-guide.md`

**Contents:**
1. Overview of adaptive engine components
2. Confidence scoring explained
3. Spaced repetition system (Leitner boxes)
4. Learning style detection
5. Adaptive game selection
6. Dynamic difficulty adjustment
7. Tuning parameters reference
8. Example learning paths
9. Troubleshooting guide
10. Performance considerations

### Technical Constraints

- Tests must be deterministic (use fixed random seeds)
- Tests should run in < 30 seconds total
- No external dependencies (mock all storage)
- Tests should be readable and self-documenting

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-20 | 1.0 | Initial story created | Sarah (PO) |

## Dev Agent Record

### Agent Model Used

_To be populated by dev agent_

### Debug Log References

_To be populated by dev agent_

### Completion Notes List

_To be populated by dev agent_

### File List

_To be populated by dev agent_

## QA Results

_To be populated by QA agent_
